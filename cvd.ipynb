{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Denoising"
      ],
      "metadata": {
        "id": "OmElnt8CZWms"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1D1smPvZRwm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from scipy import signal\n",
        "import pywt\n",
        "from scipy.signal import morlet2, spectrogram\n",
        "\n",
        "def bayesian_soft_thresholding(x, sigma_sq):\n",
        "    threshold = np.sqrt(3 * sigma_sq)\n",
        "    return np.sign(x) * np.maximum(0, np.abs(x) - threshold)\n",
        "\n",
        "def sym20_wavelet_bayesian_soft_thresholding(input_file, output_folder, num_levels):\n",
        "    # Load the PCG signal\n",
        "    sample_rate, pcg_signal = wavfile.read(input_file)\n",
        "    coeffs = pywt.wavedec(pcg_signal, 'sym20', level=num_levels)\n",
        "    thresholded_coeffs = [bayesian_soft_thresholding(c, np.var(c)) for c in coeffs]\n",
        "    reconstructed_data = pywt.waverec(thresholded_coeffs, 'sym20')\n",
        "    # Save the filtered PCG signal\n",
        "    output_file = os.path.join(output_folder, os.path.basename(input_file))\n",
        "    wavfile.write(output_file, sample_rate, reconstructed_data.astype(np.int16))\n",
        "\n",
        "\n",
        "# Get the current directory\n",
        "current_directory = os.getcwd()\n",
        "\n",
        "# List of folders containing PCG signal files\n",
        "input_folders = ['training-a', 'training-b', 'training-c', 'training-d', 'training-e', 'training-f']\n",
        "\n",
        "# Folder to save filtered PCG signal files\n",
        "output_folder = os.path.join(current_directory, 'denoised_pcg_signals')\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate over input folders\n",
        "for folder in input_folders:\n",
        "    input_folder = os.path.join(current_directory, folder)\n",
        "    # Check if the input folder exists\n",
        "    if os.path.exists(input_folder):\n",
        "        # Iterate over PCG signal files in the input folder\n",
        "        for filename in os.listdir(input_folder):\n",
        "            if filename.endswith('.wav'):\n",
        "                input_file = os.path.join(input_folder, filename)\n",
        "                # Apply Symlet wavelet with 10 decomposition levels and Bayesian soft thresholding\n",
        "                reconstructed_data = sym20_wavelet_bayesian_soft_thresholding(input_file, output_folder, num_levels=10)\n",
        "    else:\n",
        "        print(f\"Folder '{folder}' not found.\")\n",
        "\n",
        "print(\"Denoising completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bandpass filter"
      ],
      "metadata": {
        "id": "t9AJoO5xZV7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "from scipy import signal\n",
        "\n",
        "# Define function to filter PCG signals\n",
        "def filter_pcg_signal(pcg_signal, sample_rate):\n",
        "\n",
        "    # Resample the PCG signal to 1000 Hz\n",
        "    resampled_rate = 1000\n",
        "    resampled_pcg_signal = signal.resample(pcg_signal, int(len(pcg_signal) * (resampled_rate / sample_rate)))\n",
        "\n",
        "    # Define the band-pass filter parameters\n",
        "    nyquist_freq = resampled_rate / 2\n",
        "    lowcut = 20\n",
        "    highcut = 400\n",
        "    lowcut_normalized = lowcut / nyquist_freq\n",
        "    highcut_normalized = highcut / nyquist_freq\n",
        "\n",
        "    # Create the band-pass filter\n",
        "    b, a = signal.butter(4, [lowcut_normalized, highcut_normalized], btype='band')\n",
        "\n",
        "    # Apply the band-pass filter to the resampled PCG signal\n",
        "    filtered_pcg_signal = signal.filtfilt(b, a, resampled_pcg_signal)\n",
        "    return filtered_pcg_signal\n",
        "\n",
        "\n",
        "# Function to process PCG WAV file\n",
        "def process_pcg_wav_file(input_filename, output_folder):\n",
        "    # Read PCG signal from WAV file\n",
        "    fs, pcg_signal = wavfile.read(input_filename)\n",
        "\n",
        "    # Normalize the signal\n",
        "    normalised_signal = filter_pcg_signal(pcg_signal, fs)\n",
        "\n",
        "    # Get the base filename without extension\n",
        "    basename = os.path.splitext(os.path.basename(input_filename))[0]\n",
        "\n",
        "    # Specify the output filename\n",
        "    \"\"\"output_filename = os.path.join(output_folder, f\"{basename}_new_filtered.wav\")\"\"\"\n",
        "    output_filename = os.path.join(output_folder, f\"{basename}.wav\")\n",
        "\n",
        "    # Save the normalized signal as WAV file\n",
        "    wavfile.write(output_filename, fs, normalised_signal.astype(np.int16))\n",
        "\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify the input folder containing WAV files\n",
        "    input_folder = \"denoised_pcg_signals\"\n",
        "\n",
        "    # Specify the output folder for saving normalized signals\n",
        "    output_folder = \"final_filtered_pcg_signals\"\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Check if the input folder exists\n",
        "    if os.path.isdir(input_folder):\n",
        "        # Iterate over files in the input folder\n",
        "        for filename in os.listdir(input_folder):\n",
        "            if filename.endswith('.wav'):\n",
        "                input_file_path = os.path.join(input_folder, filename)\n",
        "                process_pcg_wav_file(input_file_path, output_folder)\n",
        "    else:\n",
        "        print(f\"Error: Folder '{input_folder}' not found.\")\n",
        "print(\"Bandpass Filtering completed.\")"
      ],
      "metadata": {
        "id": "JJwLmwi9aCck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scalogram generation"
      ],
      "metadata": {
        "id": "bMnCF1mSaXxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "import pywt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_scalogram(signal, wavelet='morl', scales=None):\n",
        "    if scales is None:\n",
        "        scales = range(1, 128)  # Default scales\n",
        "\n",
        "    try:\n",
        "        coefficients, frequencies = pywt.cwt(signal, scales, wavelet)\n",
        "        power = (abs(coefficients)) ** 2\n",
        "        return power, frequencies\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating scalogram for signal: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def plot_scalogram(power, frequencies):\n",
        "    plt.imshow(power, extent=[0, len(power[0]), frequencies[-1], frequencies[0]], aspect='auto', cmap='jet', vmax=np.max(power)*0.01) # Adjust the scaling factor as needed\n",
        "    plt.axis('off')\n",
        "\n",
        "def generate_and_save_scalogram(input_folder, output_folder, wavelet='morl', scales=None):\n",
        "    # Create output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate over files in the input folder\n",
        "    for filename in sorted(os.listdir(input_folder)):\n",
        "        if filename.endswith('.wav'):\n",
        "            input_file_path = os.path.join(input_folder, filename)\n",
        "            output_file_path = os.path.join(output_folder, os.path.splitext(filename)[0] + '_scalogram.png')\n",
        "\n",
        "            try:\n",
        "                # Load PCG signal from WAV file\n",
        "                fs, pcg_signal = wavfile.read(input_file_path)\n",
        "\n",
        "                # Only consider one channel if it's a stereo recording\n",
        "                if pcg_signal.ndim > 1:\n",
        "                    pcg_signal = pcg_signal[:, 0]\n",
        "\n",
        "                # Normalize signal based on maximum absolute value\n",
        "                max_abs = np.max(np.abs(pcg_signal))\n",
        "                pcg_signal = pcg_signal.astype(np.float32)\n",
        "                pcg_signal /= max_abs\n",
        "\n",
        "                # Generate scalogram\n",
        "                power, frequencies = generate_scalogram(pcg_signal, wavelet=wavelet, scales=scales)\n",
        "\n",
        "                if power is not None and frequencies is not None:\n",
        "                    # Plot and save scalogram\n",
        "                    plot_scalogram(power, frequencies)\n",
        "                    plt.savefig(output_file_path, bbox_inches='tight', pad_inches=0)\n",
        "                    plt.close()\n",
        "                    print(f\"Scalogram saved to: {output_file_path}\")\n",
        "\n",
        "                else:\n",
        "                    print(f\"Skipping processing of {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify the input folder containing normalized PCG signals\n",
        "    input_folder = \"final_filtered_pcg_signals\"\n",
        "\n",
        "    # Specify the output folder for saving scalogram images\n",
        "    output_folder = \"scalogram\"\n",
        "\n",
        "    # Generate and save scalograms for signals in the input folder\n",
        "    generate_and_save_scalogram(input_folder, output_folder)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tld1BN5IaWAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resizing Scalogram"
      ],
      "metadata": {
        "id": "lGaYY__Sae1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def resize_images(input_folder, output_folder, size=(224, 224)):\n",
        "    # Ensure the output folder exists\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Iterate over all files in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "            try:\n",
        "                # Open an image file\n",
        "                with Image.open(os.path.join(input_folder, filename)) as img:\n",
        "                    # Resize image\n",
        "                    img = img.resize(size, Image.LANCZOS)\n",
        "                    # Save it to the output folder\n",
        "                    img.save(os.path.join(output_folder, filename))\n",
        "                    print(f\"Resized and saved {filename} to {output_folder}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not process {filename}: {e}\")\n",
        "\n",
        "# Define the input and output folder paths\n",
        "input_folder = 'scalogram'\n",
        "output_folder = 'last_scalogram'\n",
        "\n",
        "# Call the resize function\n",
        "resize_images(input_folder, output_folder)"
      ],
      "metadata": {
        "id": "i6SzjCHaagn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG-19 Model"
      ],
      "metadata": {
        "id": "m3UcVEaWaiO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.applications import VGG19\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to read scalogram images from folder\n",
        "def read_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in sorted(os.listdir(folder)):\n",
        "        if filename.endswith(\".png\"):\n",
        "            img_path = os.path.join(folder, filename)\n",
        "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=(img_height, img_width))\n",
        "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "            images.append(img_array)\n",
        "    return np.array(images)\n",
        "\n",
        "def read_labels_from_csv(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    labels = df['Abnormality'].values\n",
        "    return labels\n",
        "\n",
        "# Load scalogram images and labels\n",
        "folder_path = \"resized_final_scalogram\"\n",
        "csv_file = \"output.csv\"\n",
        "img_height, img_width = 224, 224  # Define your desired image dimensions\n",
        "\n",
        "images = read_images_from_folder(folder_path)\n",
        "labels = read_labels_from_csv(csv_file)\n",
        "\n",
        "# Preprocess the data (e.g., normalization)\n",
        "images = images / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Convert labels to numerical format\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "# Load the pre-trained VGG19 model\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# Add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "# Add dropout\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# Add a logistic layer for binary classification\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# This is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Instantiate the Adam optimizer with the desired learning rate\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "# Compile the model with the Adam optimizer\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=200, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Convert predictions to binary classes\n",
        "binary_predictions = np.round(predictions).flatten()\n",
        "\n",
        "# Generate classification report\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(y_test, binary_predictions))\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, binary_predictions)\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot accuracy and loss graphs\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save or serialize the model if desired\n",
        "model.save(\"cvd_vgg19_200_model.h5\")"
      ],
      "metadata": {
        "id": "P4rUwHLIakSP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}